{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9faf50-f603-4f3c-94c3-6179c86d2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports & Config ===\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, auc)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# ---- Paths & defaults (edit if needed) ----\n",
    "INPUT_DIR  = r\"C:\\Users\\Admin\\Desktop\\ALVIN\\dataset\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\"\n",
    "\n",
    "WINDOW_SEC   = 5.0     # window length in seconds\n",
    "OVERLAP      = 0.5     # 50% overlap\n",
    "DURATION_SEC = 60.0    # seconds per file (used to infer fs)\n",
    "FS_KNOWN     = None    # set to e.g. 516.67 if you know exact fs; else leave None\n",
    "\n",
    "# Channel set (19-ch 10/20)\n",
    "CHANNELS = ['Fp1','Fp2','F3','F4','F7','F8','T3','T4','C3','C4',\n",
    "            'T5','T6','P3','P4','O1','O2','Fz','Cz','Pz']\n",
    "\n",
    "# EEG bands\n",
    "BANDS = {\n",
    "    \"Delta\": (0.5, 4.0),\n",
    "    \"Theta\": (4.0, 7.0),\n",
    "    \"Alpha\": (8.0, 13.0),\n",
    "    \"Beta\":  (13.0, 30.0),\n",
    "    \"Gamma\": (30.0, 45.0),\n",
    "}\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Ensure output dir exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# NEW: split subfolders (just dirs, not logic)\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(OUTPUT_DIR, \"val\")\n",
    "TEST_DIR  = os.path.join(OUTPUT_DIR, \"test\")\n",
    "for d in (TRAIN_DIR, VAL_DIR, TEST_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c5a7b3-a81a-4b1c-b451-563f7137c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers: I/O & labeling ===\n",
    "def likely_unlabeled(df_head, expected):\n",
    "    cols = list(df_head.columns)\n",
    "    if cols == expected:\n",
    "        return False\n",
    "    num_like = 0\n",
    "    for c in cols:\n",
    "        try:\n",
    "            float(str(c).strip()); num_like += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    return num_like >= len(cols) // 2\n",
    "\n",
    "def ensure_labeled(path, out_dir, expected_channels):\n",
    "    \"\"\"\n",
    "    Ensure an EEG CSV has proper 19-channel headers. If not, assign them and\n",
    "    save a corrected copy in OUTPUT_DIR. Returns (df, subject_id).\n",
    "    \"\"\"\n",
    "    stem = os.path.splitext(os.path.basename(path))[0]\n",
    "    try:\n",
    "        df_try = pd.read_csv(path, nrows=3)\n",
    "    except Exception:\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        df.columns = expected_channels\n",
    "        df.to_csv(os.path.join(out_dir, f\"{stem}_corrected.csv\"), index=False)\n",
    "        return df, stem\n",
    "\n",
    "    if likely_unlabeled(df_try, expected_channels):\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        df.columns = expected_channels\n",
    "        df.to_csv(os.path.join(out_dir, f\"{stem}_corrected.csv\"), index=False)\n",
    "        return df, stem\n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "        # Align if columns contain all expected channels\n",
    "        if list(df.columns) != expected_channels:\n",
    "            if set(expected_channels).issubset(set(df.columns)):\n",
    "                df = df[expected_channels]\n",
    "            else:\n",
    "                raise ValueError(f\"{path}: columns do not match expected 19 channels.\")\n",
    "        return df, stem\n",
    "\n",
    "# === Helpers: PSD & bandpowers ===\n",
    "def welch_psd(x, fs, nperseg, noverlap):\n",
    "    return welch(x, fs=fs, nperseg=int(nperseg), noverlap=int(noverlap), detrend='constant')\n",
    "\n",
    "def integrate_bandpower(f, Pxx, band):\n",
    "    fmin, fmax = band\n",
    "    idx = (f >= fmin) & (f < fmax)\n",
    "    if not np.any(idx):\n",
    "        return 0.0\n",
    "    return float(np.trapz(Pxx[idx], f[idx]))\n",
    "\n",
    "def compute_wide_summary(df, fs, bands, channels, out_csv=None):\n",
    "    \"\"\"\n",
    "    Compute absolute & relative band powers over full recording (one row).\n",
    "    \"\"\"\n",
    "    nperseg = int(4 * fs)\n",
    "    noverlap = int(0.5 * nperseg)\n",
    "    feats = {}\n",
    "    for ch in channels:\n",
    "        x = pd.to_numeric(df[ch], errors='coerce').fillna(0.0).values\n",
    "        f, Pxx = welch_psd(x, fs, nperseg, noverlap)\n",
    "        total = float(np.trapz(Pxx, f))\n",
    "        for b, rng in bands.items():\n",
    "            abs_p = integrate_bandpower(f, Pxx, rng)\n",
    "            rel_p = abs_p / total if total > 0 else np.nan\n",
    "            feats[f\"{ch}_{b}\"] = abs_p\n",
    "            feats[f\"{ch}_{b}_Rel\"] = rel_p\n",
    "    wide = pd.DataFrame([feats])\n",
    "    if out_csv:\n",
    "        wide.to_csv(out_csv, index=False)\n",
    "    return wide\n",
    "\n",
    "# === Helpers: windowing & window features ===\n",
    "def segment_windows(df, fs, win_sec, overlap):\n",
    "    win_len = int(win_sec * fs)\n",
    "    hop = max(1, int(win_len * (1 - overlap)))\n",
    "    return [(s, s + win_len) for s in range(0, len(df) - win_len + 1, hop)]\n",
    "\n",
    "def compute_window_features(df, fs, window, bands, channels):\n",
    "    s, e = window\n",
    "    xw = df.iloc[s:e]\n",
    "    nperseg = max(4, int(2 * fs))\n",
    "    noverlap = int(0.5 * nperseg)\n",
    "    feats = {}\n",
    "    for ch in channels:\n",
    "        x = pd.to_numeric(xw[ch], errors='coerce').fillna(0.0).values\n",
    "        f, Pxx = welch_psd(x, fs, nperseg, noverlap)\n",
    "        total = float(np.trapz(Pxx, f))\n",
    "        for b, rng in bands.items():\n",
    "            abs_p = integrate_bandpower(f, Pxx, rng)\n",
    "            rel_p = abs_p / total if total > 0 else np.nan\n",
    "            feats[f\"{ch}_{b}\"] = abs_p\n",
    "            feats[f\"{ch}_{b}_Rel\"] = rel_p\n",
    "    feats[\"StartSample\"] = s\n",
    "    feats[\"Fs\"] = fs\n",
    "    return feats\n",
    "\n",
    "# === Optional plotting helpers ===\n",
    "def plot_psd_per_subject(df, fs, channels, out_path, subj):\n",
    "    nperseg = int(4 * fs)\n",
    "    noverlap = int(0.5 * nperseg)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for ch in channels:\n",
    "        x = pd.to_numeric(df[ch], errors='coerce').fillna(0.0).values\n",
    "        f, Pxx = welch_psd(x, fs, nperseg, noverlap)\n",
    "        plt.plot(f, 10*np.log10(Pxx), label=ch)\n",
    "    plt.xlim(0, 50)\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Power Spectral Density (dB/Hz)\")\n",
    "    plt.title(f\"EEG Channel PSDs — {subj}\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_band_bars(wide_df, channels, bands, out_abs, out_rel, subj):\n",
    "    xs = np.arange(len(channels))\n",
    "    width = 0.15\n",
    "    band_list = list(bands.keys())\n",
    "\n",
    "    # Absolute\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for i, b in enumerate(band_list):\n",
    "        vals = [wide_df[f\"{ch}_{b}\"].values[0] for ch in channels]\n",
    "        plt.bar(xs + i*width, vals, width, label=b)\n",
    "    plt.xticks(xs + width*2, channels, rotation=45)\n",
    "    plt.ylabel(\"Absolute Band Power\")\n",
    "    plt.title(f\"Band Powers per Channel (Absolute) — {subj}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_abs, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Relative\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for i, b in enumerate(band_list):\n",
    "        vals = [wide_df[f\"{ch}_{b}_Rel\"].values[0] for ch in channels]\n",
    "        plt.bar(xs + i*width, vals, width, label=b)\n",
    "    plt.xticks(xs + width*2, channels, rotation=45)\n",
    "    plt.ylabel(\"Relative Band Power\")\n",
    "    plt.title(f\"Band Powers per Channel (Relative) — {subj}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_rel, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841d68af-6fa3-417c-9c99-a2610041b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 file(s): s00.csv, s01.csv, s02.csv, s03.csv, s04.csv, s05.csv, s06.csv, s07.csv, s08.csv, s09.csv, s10.csv, s11.csv, s12.csv, s13.csv, s14.csv, s15.csv, s16.csv, s17.csv, s18.csv, s19.csv, s20.csv, s21.csv, s22.csv, s23.csv, s24.csv, s25.csv, s26.csv, s27.csv, s28.csv, s29.csv, s30.csv, s31.csv, s32.csv, s33.csv, s34.csv, s35.csv\n",
      "[s00] samples=31000, fs=516.6667 Hz\n",
      "[s01] samples=31000, fs=516.6667 Hz\n",
      "[s02] samples=31000, fs=516.6667 Hz\n",
      "[s03] samples=31000, fs=516.6667 Hz\n",
      "[s04] samples=31000, fs=516.6667 Hz\n",
      "[s05] samples=31000, fs=516.6667 Hz\n",
      "[s06] samples=31000, fs=516.6667 Hz\n",
      "[s07] samples=31000, fs=516.6667 Hz\n",
      "[s08] samples=31000, fs=516.6667 Hz\n",
      "[s09] samples=31000, fs=516.6667 Hz\n",
      "[s10] samples=31000, fs=516.6667 Hz\n",
      "[s11] samples=31000, fs=516.6667 Hz\n",
      "[s12] samples=31000, fs=516.6667 Hz\n",
      "[s13] samples=31000, fs=516.6667 Hz\n",
      "[s14] samples=31000, fs=516.6667 Hz\n",
      "[s15] samples=31000, fs=516.6667 Hz\n",
      "[s16] samples=31000, fs=516.6667 Hz\n",
      "[s17] samples=31000, fs=516.6667 Hz\n",
      "[s18] samples=31000, fs=516.6667 Hz\n",
      "[s19] samples=31000, fs=516.6667 Hz\n",
      "[s20] samples=31000, fs=516.6667 Hz\n",
      "[s21] samples=31000, fs=516.6667 Hz\n",
      "[s22] samples=31000, fs=516.6667 Hz\n",
      "[s23] samples=31000, fs=516.6667 Hz\n",
      "[s24] samples=31000, fs=516.6667 Hz\n",
      "[s25] samples=31000, fs=516.6667 Hz\n",
      "[s26] samples=31000, fs=516.6667 Hz\n",
      "[s27] samples=31000, fs=516.6667 Hz\n",
      "[s28] samples=31000, fs=516.6667 Hz\n",
      "[s29] samples=31000, fs=516.6667 Hz\n",
      "[s30] samples=31000, fs=516.6667 Hz\n",
      "[s31] samples=31000, fs=516.6667 Hz\n",
      "[s32] samples=31000, fs=516.6667 Hz\n",
      "[s33] samples=31000, fs=516.6667 Hz\n",
      "[s34] samples=31000, fs=516.6667 Hz\n",
      "[s35] samples=31000, fs=516.6667 Hz\n",
      "Saved master features: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\eeg_biometric_features_5s_master.csv\n",
      "Subjects processed: ['s00', 's01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30', 's31', 's32', 's33', 's34', 's35']\n"
     ]
    }
   ],
   "source": [
    "# === Process all subjects: per-subject wide summary + windowed master features ===\n",
    "make_plots = True  # set False if you don't want per-subject plots\n",
    "\n",
    "# Discover input CSVs (ignore previous outputs)\n",
    "files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(\".csv\")]\n",
    "exclude = re.compile(r\"(bandpowers|features|corrected|wide|master|model|report|roc|cm)\", re.I)\n",
    "candidates = [f for f in files if not exclude.search(f)]\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"No CSVs found in {INPUT_DIR}\")\n",
    "\n",
    "print(f\"Found {len(candidates)} file(s):\", \", \".join(sorted(candidates)))\n",
    "\n",
    "master_rows = []\n",
    "subjects = []\n",
    "wide_paths = []\n",
    "\n",
    "for fname in sorted(candidates):\n",
    "    path = os.path.join(INPUT_DIR, fname)\n",
    "    df, subj = ensure_labeled(path, OUTPUT_DIR, CHANNELS)\n",
    "    subjects.append(subj)\n",
    "\n",
    "    # fs: known or inferred\n",
    "    fs = FS_KNOWN if FS_KNOWN else (df.shape[0] / float(DURATION_SEC))\n",
    "    print(f\"[{subj}] samples={len(df)}, fs={fs:.4f} Hz\")\n",
    "\n",
    "    # Wide summary (full 60 s)\n",
    "    wide_csv = os.path.join(OUTPUT_DIR, f\"{subj}_bandpowers_wide.csv\")\n",
    "    wide = compute_wide_summary(df, fs, BANDS, CHANNELS, out_csv=wide_csv)\n",
    "    wide_paths.append(wide_csv)\n",
    "\n",
    "    # Optional subject plots\n",
    "    if make_plots:\n",
    "        plot_psd_per_subject(df, fs, CHANNELS, os.path.join(OUTPUT_DIR, f\"psd_{subj}.png\"), subj)\n",
    "        plot_band_bars(wide, CHANNELS, BANDS,\n",
    "                       os.path.join(OUTPUT_DIR, f\"band_abs_{subj}.png\"),\n",
    "                       os.path.join(OUTPUT_DIR, f\"band_rel_{subj}.png\"),\n",
    "                       subj)\n",
    "\n",
    "    # Windowed features\n",
    "    windows = segment_windows(df, fs, WINDOW_SEC, OVERLAP)\n",
    "    for w in windows:\n",
    "        feats = compute_window_features(df, fs, w, BANDS, CHANNELS)\n",
    "        feats[\"Subject\"] = subj\n",
    "        master_rows.append(feats)\n",
    "\n",
    "# Save master features\n",
    "if not master_rows:\n",
    "    raise RuntimeError(\"No windowed features produced. Check WINDOW_SEC/OVERLAP vs. file length.\")\n",
    "\n",
    "master = pd.DataFrame(master_rows)\n",
    "master_csv = os.path.join(OUTPUT_DIR, f\"eeg_biometric_features_{int(WINDOW_SEC)}s_master.csv\")\n",
    "master.to_csv(master_csv, index=False)\n",
    "print(\"Saved master features:\", master_csv)\n",
    "print(\"Subjects processed:\", sorted(set(subjects)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb69243-1aec-49e3-ae36-8bf3256e2ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved splits:\n",
      " - TRAIN: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\train\\eeg_biometric_features_train.csv (496, 193)\n",
      " - VAL  : C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\val\\eeg_biometric_features_val.csv (166, 193)\n",
      " - TEST : C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\test\\eeg_biometric_features_test.csv (166, 193)\n"
     ]
    }
   ],
   "source": [
    "# === NEW: Create stratified Train/Validation/Test splits (60/20/20) and save ===\n",
    "dfm_full = pd.read_csv(master_csv)\n",
    "\n",
    "# We stratify by \"Subject\"\n",
    "y_all = dfm_full[\"Subject\"].values\n",
    "\n",
    "# 1) TEST = 20% (hidden)\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=RANDOM_SEED)\n",
    "trainval_idx, test_idx = next(sss1.split(dfm_full, y_all))\n",
    "\n",
    "# 2) From remaining 80%, VAL = 25% of that -> 20% overall\n",
    "y_trainval = y_all[trainval_idx]\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=RANDOM_SEED)\n",
    "train_idx_rel, val_idx_rel = next(sss2.split(dfm_full.iloc[trainval_idx], y_trainval))\n",
    "\n",
    "train_idx = trainval_idx[train_idx_rel]\n",
    "val_idx   = trainval_idx[val_idx_rel]\n",
    "\n",
    "df_train = dfm_full.iloc[train_idx].reset_index(drop=True)\n",
    "df_val   = dfm_full.iloc[val_idx].reset_index(drop=True)\n",
    "df_test  = dfm_full.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "train_csv = os.path.join(TRAIN_DIR, \"eeg_biometric_features_train.csv\")\n",
    "val_csv   = os.path.join(VAL_DIR,   \"eeg_biometric_features_val.csv\")\n",
    "test_csv  = os.path.join(TEST_DIR,  \"eeg_biometric_features_test.csv\")\n",
    "\n",
    "df_train.to_csv(train_csv, index=False)\n",
    "df_val.to_csv(val_csv, index=False)\n",
    "df_test.to_csv(test_csv, index=False)\n",
    "\n",
    "print(\"Saved splits:\")\n",
    "print(\" - TRAIN:\", train_csv, df_train.shape)\n",
    "print(\" - VAL  :\", val_csv,   df_val.shape)\n",
    "print(\" - TEST :\", test_csv,  df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c629f6-0347-4e5d-95f6-4db11fd3d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] CV acc=0.9919 | VAL acc=0.9880 | best={'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 500}\n",
      "[SVM_RBF] CV acc=0.9637 | VAL acc=0.9759 | best={'clf__C': 10, 'clf__gamma': 0.001}\n",
      "\n",
      "Selected model: RandomForest | VAL acc=0.9880 | CV=0.9919 | params={'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 500}\n",
      "Saved tuned model: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\chosen_RandomForest_train_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "# === Modeling setup: load splits, define utilities (same helpers reused) ===\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_val   = pd.read_csv(val_csv)\n",
    "\n",
    "FEATURE_DROP = [\"Subject\", \"StartSample\", \"Fs\"]\n",
    "\n",
    "X_tr = df_train.drop(columns=FEATURE_DROP, errors=\"ignore\").values\n",
    "y_tr = df_train[\"Subject\"].values\n",
    "X_va = df_val.drop(columns=FEATURE_DROP, errors=\"ignore\").values\n",
    "y_va = df_val[\"Subject\"].values\n",
    "\n",
    "CLASSES = sorted(pd.concat([df_train[\"Subject\"], df_val[\"Subject\"]]).unique().tolist())\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, out_path, title):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', fontsize=8)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def compute_ovr_roc_eer(proba, y_true, class_names, out_png, out_csv):\n",
    "    Y = label_binarize(y_true, classes=class_names)\n",
    "    aucs, eers = [], []\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for i, cname in enumerate(class_names):\n",
    "        fpr, tpr, thr = roc_curve(Y[:, i], proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fnr = 1 - tpr\n",
    "        idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "        eer = float((fnr[idx] + fpr[idx]) / 2.0)\n",
    "        aucs.append(float(roc_auc)); eers.append(float(eer))\n",
    "        plt.plot(fpr, tpr, label=f\"{cname} AUC={roc_auc:.3f}, EER={eer:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'--', lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"One-vs-Rest ROC\")\n",
    "    plt.legend(fontsize=7, loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    df = pd.DataFrame({\"Class\": class_names, \"AUC\": aucs, \"EER\": eers})\n",
    "    df.loc[len(df)] = [\"macro_avg\", float(np.mean(aucs)), float(np.mean(eers))]\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "# Pipelines & grids (unchanged from old code)\n",
    "rf_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", RandomForestClassifier(random_state=RANDOM_SEED))\n",
    "])\n",
    "rf_grid = {\n",
    "    \"clf__n_estimators\": [300, 500],\n",
    "    \"clf__max_depth\": [None, 12, 18],\n",
    "    \"clf__min_samples_leaf\": [1, 2],\n",
    "}\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_SEED))\n",
    "])\n",
    "svm_grid = {\n",
    "    \"clf__C\": [1, 5, 10],\n",
    "    \"clf__gamma\": [\"scale\", 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# CV on TRAIN only; choose by VAL accuracy\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "candidates = []\n",
    "for name, pipe, grid in [(\"RandomForest\", rf_pipe, rf_grid), (\"SVM_RBF\", svm_pipe, svm_grid)]:\n",
    "    gs = GridSearchCV(pipe, grid, cv=skf, n_jobs=-1, scoring=\"accuracy\", verbose=0)\n",
    "    gs.fit(X_tr, y_tr)\n",
    "    best = gs.best_estimator_\n",
    "    val_acc = accuracy_score(y_va, best.predict(X_va))\n",
    "    candidates.append((name, best, gs.best_params_, gs.best_score_, val_acc))\n",
    "    print(f\"[{name}] CV acc={gs.best_score_:.4f} | VAL acc={val_acc:.4f} | best={gs.best_params_}\")\n",
    "\n",
    "# Select by validation accuracy (tie-breaker: CV acc)\n",
    "candidates.sort(key=lambda t: (t[4], t[3]), reverse=True)\n",
    "best_name, best_model, best_params, best_cv_acc, best_val_acc = candidates[0]\n",
    "print(f\"\\nSelected model: {best_name} | VAL acc={best_val_acc:.4f} | CV={best_cv_acc:.4f} | params={best_params}\")\n",
    "\n",
    "# Save tuned (train-only) model\n",
    "tmp_model_path = os.path.join(OUTPUT_DIR, f\"chosen_{best_name}_train_tuned.joblib\")\n",
    "joblib.dump(best_model, tmp_model_path)\n",
    "print(\"Saved tuned model:\", tmp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c0579c-9cf1-47a5-ae02-a94f98edb8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL] RandomForest — TEST accuracy = 0.9819\n",
      "Saved: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\cm_TEST_RandomForest.png\n",
      "Saved: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\roc_TEST_RandomForest.png\n",
      "Saved: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\verification_TEST_RandomForest.csv\n",
      "Saved: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\class_report_TEST_RandomForest.csv\n",
      "Saved: C:\\Users\\Admin\\Desktop\\ALVIN\\outputs 1\\final_RandomForest_trainval.joblib\n"
     ]
    }
   ],
   "source": [
    "# Load TEST and merge TRAIN+VAL\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_trainval = pd.concat([df_train, df_val], axis=0, ignore_index=True)\n",
    "\n",
    "X_trva = df_trainval.drop(columns=FEATURE_DROP, errors=\"ignore\").values\n",
    "y_trva = df_trainval[\"Subject\"].values\n",
    "\n",
    "X_te = df_test.drop(columns=FEATURE_DROP, errors=\"ignore\").values\n",
    "y_te = df_test[\"Subject\"].values\n",
    "\n",
    "# Retrain chosen model on TRAIN+VAL\n",
    "final_model = joblib.load(os.path.join(OUTPUT_DIR, f\"chosen_{best_name}_train_tuned.joblib\"))\n",
    "final_model.fit(X_trva, y_trva)\n",
    "\n",
    "# TEST evaluation\n",
    "y_pred = final_model.predict(X_te)\n",
    "test_acc = accuracy_score(y_te, y_pred)\n",
    "print(f\"[FINAL] {best_name} — TEST accuracy = {test_acc:.4f}\")\n",
    "\n",
    "# Confusion Matrix (TEST)\n",
    "CLASSES_ALL = sorted(pd.concat([df_trainval[\"Subject\"], df_test[\"Subject\"]]).unique().tolist())\n",
    "cm = confusion_matrix(y_te, y_pred, labels=CLASSES_ALL)\n",
    "cm_png = os.path.join(OUTPUT_DIR, f\"cm_TEST_{best_name}.png\")\n",
    "plot_confusion_matrix(cm, CLASSES_ALL, cm_png, f\"Confusion Matrix — TEST — {best_name} (acc={test_acc:.3f})\")\n",
    "print(\"Saved:\", cm_png)\n",
    "\n",
    "# ROC / AUC / EER (TEST)\n",
    "proba_te = final_model.predict_proba(X_te)\n",
    "roc_png = os.path.join(OUTPUT_DIR, f\"roc_TEST_{best_name}.png\")\n",
    "verif_csv = os.path.join(OUTPUT_DIR, f\"verification_TEST_{best_name}.csv\")\n",
    "compute_ovr_roc_eer(proba_te, y_te, CLASSES_ALL, roc_png, verif_csv)\n",
    "print(\"Saved:\", roc_png)\n",
    "print(\"Saved:\", verif_csv)\n",
    "\n",
    "# Classification report (TEST)\n",
    "rep_csv = os.path.join(OUTPUT_DIR, f\"class_report_TEST_{best_name}.csv\")\n",
    "pd.DataFrame(classification_report(y_te, y_pred, labels=CLASSES_ALL, output_dict=True)).transpose().to_csv(rep_csv)\n",
    "print(\"Saved:\", rep_csv)\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(OUTPUT_DIR, f\"final_{best_name}_trainval.joblib\")\n",
    "joblib.dump(final_model, final_model_path)\n",
    "print(\"Saved:\", final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f54118-8058-4c6e-828c-16a31d3fcef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
